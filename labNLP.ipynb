{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kshitijv256/lab_files/blob/main/labNLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.Tokenization**"
      ],
      "metadata": {
        "id": "xUOUllNQrlt6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk"
      ],
      "metadata": {
        "id": "2oBbYcTi34XD"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize,word_tokenize"
      ],
      "metadata": {
        "id": "PGitbJFA34qo"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQ2DptfOr5ye",
        "outputId": "788d1baa-b353-465f-9583-3ca3ac352d21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example=\"Good Morning everyone!! Today we will study nltk.\""
      ],
      "metadata": {
        "id": "EuOIL4w6sAuW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sent_tokenize(example))\n",
        "print(word_tokenize(example))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WGMob0KmsBU4",
        "outputId": "1e73dce9-4f52-4287-c1a3-73e533d3e0df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Good Morning everyone!!', 'Today we will study nltk.']\n",
            "['Good', 'Morning', 'everyone', '!', '!', 'Today', 'we', 'will', 'study', 'nltk', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in(sent_tokenize(example)):\n",
        "  print(i)\n",
        "  for j in (word_tokenize(example)):\n",
        "    print(j)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01bP-7A0sBXe",
        "outputId": "e9df6b9c-86e5-448c-8623-772076413b9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Good Morning everyone!!\n",
            "Good\n",
            "Morning\n",
            "everyone\n",
            "!\n",
            "!\n",
            "Today\n",
            "we\n",
            "will\n",
            "study\n",
            "nltk\n",
            ".\n",
            "Today we will study nltk.\n",
            "Good\n",
            "Morning\n",
            "everyone\n",
            "!\n",
            "!\n",
            "Today\n",
            "we\n",
            "will\n",
            "study\n",
            "nltk\n",
            ".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**02.stopwrds**"
      ],
      "metadata": {
        "id": "WaoF07-Ctk1R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import  nltk.corpus\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download(\"stopwords\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fERiqLZfsBZ-",
        "outputId": "f900667b-d80f-4e91-85ff-d4f5b1cee8e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words=set(stopwords.words(\"english\"))"
      ],
      "metadata": {
        "id": "C-f4oNOesBcu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example=\"Good morning everyone.Today we will study NLTK.\"\n",
        "words=word_tokenize(example)\n",
        "remove_stopwords=[]"
      ],
      "metadata": {
        "id": "iOT5YODysBgC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in words:\n",
        "  if i not in stop_words:\n",
        "    remove_stopwords.append(i)\n",
        "print(remove_stopwords)\n",
        "removed_words=[i for i in words if i in stop_words]\n",
        "print(removed_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V4g4OQMPxRb_",
        "outputId": "3ddc316e-71ca-4cb2-9de8-6d916c50a8f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Good', 'morning', 'everyone.Today', 'study', 'NLTK', '.']\n",
            "['we', 'will']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9msTHMs4zFkA",
        "outputId": "c74ac6b5-b8f3-4899-d794-55fd78a69de7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'a',\n",
              " 'about',\n",
              " 'above',\n",
              " 'after',\n",
              " 'again',\n",
              " 'against',\n",
              " 'ain',\n",
              " 'all',\n",
              " 'am',\n",
              " 'an',\n",
              " 'and',\n",
              " 'any',\n",
              " 'are',\n",
              " 'aren',\n",
              " \"aren't\",\n",
              " 'as',\n",
              " 'at',\n",
              " 'be',\n",
              " 'because',\n",
              " 'been',\n",
              " 'before',\n",
              " 'being',\n",
              " 'below',\n",
              " 'between',\n",
              " 'both',\n",
              " 'but',\n",
              " 'by',\n",
              " 'can',\n",
              " 'couldn',\n",
              " \"couldn't\",\n",
              " 'd',\n",
              " 'did',\n",
              " 'didn',\n",
              " \"didn't\",\n",
              " 'do',\n",
              " 'does',\n",
              " 'doesn',\n",
              " \"doesn't\",\n",
              " 'doing',\n",
              " 'don',\n",
              " \"don't\",\n",
              " 'down',\n",
              " 'during',\n",
              " 'each',\n",
              " 'few',\n",
              " 'for',\n",
              " 'from',\n",
              " 'further',\n",
              " 'had',\n",
              " 'hadn',\n",
              " \"hadn't\",\n",
              " 'has',\n",
              " 'hasn',\n",
              " \"hasn't\",\n",
              " 'have',\n",
              " 'haven',\n",
              " \"haven't\",\n",
              " 'having',\n",
              " 'he',\n",
              " 'her',\n",
              " 'here',\n",
              " 'hers',\n",
              " 'herself',\n",
              " 'him',\n",
              " 'himself',\n",
              " 'his',\n",
              " 'how',\n",
              " 'i',\n",
              " 'if',\n",
              " 'in',\n",
              " 'into',\n",
              " 'is',\n",
              " 'isn',\n",
              " \"isn't\",\n",
              " 'it',\n",
              " \"it's\",\n",
              " 'its',\n",
              " 'itself',\n",
              " 'just',\n",
              " 'll',\n",
              " 'm',\n",
              " 'ma',\n",
              " 'me',\n",
              " 'mightn',\n",
              " \"mightn't\",\n",
              " 'more',\n",
              " 'most',\n",
              " 'mustn',\n",
              " \"mustn't\",\n",
              " 'my',\n",
              " 'myself',\n",
              " 'needn',\n",
              " \"needn't\",\n",
              " 'no',\n",
              " 'nor',\n",
              " 'not',\n",
              " 'now',\n",
              " 'o',\n",
              " 'of',\n",
              " 'off',\n",
              " 'on',\n",
              " 'once',\n",
              " 'only',\n",
              " 'or',\n",
              " 'other',\n",
              " 'our',\n",
              " 'ours',\n",
              " 'ourselves',\n",
              " 'out',\n",
              " 'over',\n",
              " 'own',\n",
              " 're',\n",
              " 's',\n",
              " 'same',\n",
              " 'shan',\n",
              " \"shan't\",\n",
              " 'she',\n",
              " \"she's\",\n",
              " 'should',\n",
              " \"should've\",\n",
              " 'shouldn',\n",
              " \"shouldn't\",\n",
              " 'so',\n",
              " 'some',\n",
              " 'such',\n",
              " 't',\n",
              " 'than',\n",
              " 'that',\n",
              " \"that'll\",\n",
              " 'the',\n",
              " 'their',\n",
              " 'theirs',\n",
              " 'them',\n",
              " 'themselves',\n",
              " 'then',\n",
              " 'there',\n",
              " 'these',\n",
              " 'they',\n",
              " 'this',\n",
              " 'those',\n",
              " 'through',\n",
              " 'to',\n",
              " 'too',\n",
              " 'under',\n",
              " 'until',\n",
              " 'up',\n",
              " 've',\n",
              " 'very',\n",
              " 'was',\n",
              " 'wasn',\n",
              " \"wasn't\",\n",
              " 'we',\n",
              " 'were',\n",
              " 'weren',\n",
              " \"weren't\",\n",
              " 'what',\n",
              " 'when',\n",
              " 'where',\n",
              " 'which',\n",
              " 'while',\n",
              " 'who',\n",
              " 'whom',\n",
              " 'why',\n",
              " 'will',\n",
              " 'with',\n",
              " 'won',\n",
              " \"won't\",\n",
              " 'wouldn',\n",
              " \"wouldn't\",\n",
              " 'y',\n",
              " 'you',\n",
              " \"you'd\",\n",
              " \"you'll\",\n",
              " \"you're\",\n",
              " \"you've\",\n",
              " 'your',\n",
              " 'yours',\n",
              " 'yourself',\n",
              " 'yourselves'}"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**03. Stemming**"
      ],
      "metadata": {
        "id": "ip33yUaOzL80"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer,SnowballStemmer  #Snowball is more aggressive, supports multiple languages and is more accurate for English text"
      ],
      "metadata": {
        "id": "av-lksrYzPNd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ps=PorterStemmer()\n",
        "sb=SnowballStemmer('english')\n",
        "words=['computer','computerization','computerize']\n",
        "for i in words:\n",
        "  print(i+\" :\"+ps.stem(i))\n",
        "print('------------------------------')\n",
        "for i in words:\n",
        "  print(i+\" :\"+sb.stem(i))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "scZH-5rUzhfD",
        "outputId": "cea12a5c-7186-4229-c156-bb65a5345abe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "computer :comput\n",
            "computerization :computer\n",
            "computerize :computer\n",
            "------------------------------\n",
            "computer :comput\n",
            "computerization :computer\n",
            "computerize :computer\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**04.POS TAGGING of a given sentence**[link text](https://)"
      ],
      "metadata": {
        "id": "CPiIRHH-0ihN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import state_union\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize,PunktSentenceTokenizer\n"
      ],
      "metadata": {
        "id": "aaNZfFtl0hGD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3rKAQMkB6BeA",
        "outputId": "e666629d-dc8a-4977-9531-88a11d638548"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text=\"Good morning everyone. Today we will study NLTK.\"\n",
        "custom=sent_tokenize(text)\n",
        "print(custom)\n",
        "custom_tokenizer=PunktSentenceTokenizer(text)\n",
        "tokenized=custom_tokenizer.tokenize(text)\n",
        "print(tokenized)\n",
        "def process_content():\n",
        "  try:\n",
        "    for i in tokenized:\n",
        "      words=nltk.word_tokenize(i)\n",
        "      tagged=nltk.pos_tag(words)\n",
        "    print(tagged)\n",
        "  except Exception as e:\n",
        "    print(str(e))\n",
        "process_content()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9qLvD9we1Ac7",
        "outputId": "7b9afcf9-0449-43f7-9e01-2bc7405ea337"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Good morning everyone.', 'Today we will study NLTK.']\n",
            "['Good morning everyone.', 'Today we will study NLTK.']\n",
            "[('Today', 'NN'), ('we', 'PRP'), ('will', 'MD'), ('study', 'VB'), ('NLTK', 'NNP'), ('.', '.')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**05. Stemming on austen-emma**"
      ],
      "metadata": {
        "id": "3c-yFgbw6qIR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from urllib import request\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "url='https://github.com/fbkarsdorp/python-course/raw/master/data/austen-emma.txt'\n",
        "res=request.urlopen(url)\n",
        "text=res.read().decode('utf-8')\n",
        "ps=PorterStemmer()\n",
        "tokenized=[sent_tokenize(text)[3],sent_tokenize(text)[4]]\n",
        "for i in tokenized:\n",
        "  for f in word_tokenize(i):\n",
        "    print(f+\" :\"+ps.stem(f))\n",
        "  print('\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M7NJfYRL1stl",
        "outputId": "1efa4cd8-36d1-4181-f954-2b93fc8e9ddd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sixteen :sixteen\n",
            "years :year\n",
            "had :had\n",
            "Miss :miss\n",
            "Taylor :taylor\n",
            "been :been\n",
            "in :in\n",
            "Mr. :mr.\n",
            "Woodhouse :woodhous\n",
            "'s :'s\n",
            "family :famili\n",
            ", :,\n",
            "less :less\n",
            "as :as\n",
            "a :a\n",
            "governess :gover\n",
            "than :than\n",
            "a :a\n",
            "friend :friend\n",
            ", :,\n",
            "very :veri\n",
            "fond :fond\n",
            "of :of\n",
            "both :both\n",
            "daughters :daughter\n",
            ", :,\n",
            "but :but\n",
            "particularly :particularli\n",
            "of :of\n",
            "Emma :emma\n",
            ". :.\n",
            "\n",
            "\n",
            "Between :between\n",
            "_them_ :_them_\n",
            "it :it\n",
            "was :wa\n",
            "more :more\n",
            "the :the\n",
            "intimacy :intimaci\n",
            "of :of\n",
            "sisters :sister\n",
            ". :.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**06. N-Grams**\n"
      ],
      "metadata": {
        "id": "ijgupaFp7_zj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.util import ngrams\n",
        "text=\"Good morning everyone. Today we will study NLTK. It is all about Natural Language Processing!\"\n",
        "tokens=word_tokenize(text)\n",
        "ngrams_list=list(ngrams(tokens,3))\n",
        "print(ngrams_list)\n",
        "#for item in ngrams_list:\n",
        "#  print(item)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bDllj5sC8FEk",
        "outputId": "646cb43f-4d41-478f-c251-45da7e0fef8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Good', 'morning', 'everyone'), ('morning', 'everyone', '.'), ('everyone', '.', 'Today'), ('.', 'Today', 'we'), ('Today', 'we', 'will'), ('we', 'will', 'study'), ('will', 'study', 'NLTK'), ('study', 'NLTK', '.'), ('NLTK', '.', 'It'), ('.', 'It', 'is'), ('It', 'is', 'all'), ('is', 'all', 'about'), ('all', 'about', 'Natural'), ('about', 'Natural', 'Language'), ('Natural', 'Language', 'Processing'), ('Language', 'Processing', '!')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**07.tokenization & POS tagging of austem Emma**"
      ],
      "metadata": {
        "id": "HTO9du2R89fj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from urllib import request\n",
        "from nltk.tokenize import word_tokenize, PunktSentenceTokenizer"
      ],
      "metadata": {
        "id": "ILc5I72s8FVj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url='https://github.com/fbkarsdorp/python-course/raw/master/data/austen-emma.txt'\n",
        "res=request.urlopen(url)\n",
        "text=res.read().decode('utf-8')\n",
        "custom=PunktSentenceTokenizer(text)\n",
        "tokenized=custom.tokenize(text[:1301])\n",
        "print('Tokenized Sentences:')\n",
        "for item in tokenized:\n",
        "  print(item)\n",
        "print('\\nPOS Tagging:')\n",
        "\n",
        "def process_content():\n",
        "  try:\n",
        "    for i in tokenized:\n",
        "      words=word_tokenize(i)\n",
        "      tagged=nltk.pos_tag(words)\n",
        "      print(tagged)\n",
        "  except Exception as e:\n",
        "    print(str(e))\n",
        "process_content()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DFJcXZ4g8FYI",
        "outputId": "218e9dfb-a116-48d8-a8a6-0a5c42349024"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenized Sentences:\n",
            "[Emma by Jane Austen 1816]\n",
            "\n",
            "VOLUME I\n",
            "\n",
            "CHAPTER I\n",
            "\n",
            "\n",
            "Emma Woodhouse, handsome, clever, and rich, with a comfortable home\n",
            "and happy disposition, seemed to unite some of the best blessings\n",
            "of existence; and had lived nearly twenty-one years in the world\n",
            "with very little to distress or vex her.\n",
            "She was the youngest of the two daughters of a most affectionate,\n",
            "indulgent father; and had, in consequence of her sister's marriage,\n",
            "been mistress of his house from a very early period.\n",
            "Her mother\n",
            "had died too long ago for her to have more than an indistinct\n",
            "remembrance of her caresses; and her place had been supplied\n",
            "by an excellent woman as governess, who had fallen little short\n",
            "of a mother in affection.\n",
            "Sixteen years had Miss Taylor been in Mr. Woodhouse's family,\n",
            "less as a governess than a friend, very fond of both daughters,\n",
            "but particularly of Emma.\n",
            "Between _them_ it was more the intimacy\n",
            "of sisters.\n",
            "Even before Miss Taylor had ceased to hold the nominal\n",
            "office of governess, the mildness of her temper had hardly allowed\n",
            "her to impose any restraint; and the shadow of authority being\n",
            "now long passed away, they had been living together as friend and\n",
            "friend very mutually attached, and Emma doing just what she liked;\n",
            "highly esteeming Miss Taylor's judgment, but directed chiefly by\n",
            "her own.\n",
            "\n",
            "POS Tagging:\n",
            "[('[', 'NNS'), ('Emma', 'NNP'), ('by', 'IN'), ('Jane', 'NNP'), ('Austen', 'NNP'), ('1816', 'CD'), (']', 'NNP'), ('VOLUME', 'NNP'), ('I', 'PRP'), ('CHAPTER', 'VBP'), ('I', 'PRP'), ('Emma', 'NNP'), ('Woodhouse', 'NNP'), (',', ','), ('handsome', 'NN'), (',', ','), ('clever', 'NN'), (',', ','), ('and', 'CC'), ('rich', 'JJ'), (',', ','), ('with', 'IN'), ('a', 'DT'), ('comfortable', 'JJ'), ('home', 'NN'), ('and', 'CC'), ('happy', 'JJ'), ('disposition', 'NN'), (',', ','), ('seemed', 'VBD'), ('to', 'TO'), ('unite', 'VB'), ('some', 'DT'), ('of', 'IN'), ('the', 'DT'), ('best', 'JJS'), ('blessings', 'NNS'), ('of', 'IN'), ('existence', 'NN'), (';', ':'), ('and', 'CC'), ('had', 'VBD'), ('lived', 'VBN'), ('nearly', 'RB'), ('twenty-one', 'CD'), ('years', 'NNS'), ('in', 'IN'), ('the', 'DT'), ('world', 'NN'), ('with', 'IN'), ('very', 'RB'), ('little', 'JJ'), ('to', 'TO'), ('distress', 'VB'), ('or', 'CC'), ('vex', 'VB'), ('her', 'PRP'), ('.', '.')]\n",
            "[('She', 'PRP'), ('was', 'VBD'), ('the', 'DT'), ('youngest', 'JJS'), ('of', 'IN'), ('the', 'DT'), ('two', 'CD'), ('daughters', 'NNS'), ('of', 'IN'), ('a', 'DT'), ('most', 'RBS'), ('affectionate', 'JJ'), (',', ','), ('indulgent', 'JJ'), ('father', 'NN'), (';', ':'), ('and', 'CC'), ('had', 'VBD'), (',', ','), ('in', 'IN'), ('consequence', 'NN'), ('of', 'IN'), ('her', 'PRP$'), ('sister', 'NN'), (\"'s\", 'POS'), ('marriage', 'NN'), (',', ','), ('been', 'VBN'), ('mistress', 'NN'), ('of', 'IN'), ('his', 'PRP$'), ('house', 'NN'), ('from', 'IN'), ('a', 'DT'), ('very', 'RB'), ('early', 'JJ'), ('period', 'NN'), ('.', '.')]\n",
            "[('Her', 'PRP$'), ('mother', 'NN'), ('had', 'VBD'), ('died', 'VBN'), ('too', 'RB'), ('long', 'RB'), ('ago', 'RB'), ('for', 'IN'), ('her', 'PRP$'), ('to', 'TO'), ('have', 'VB'), ('more', 'JJR'), ('than', 'IN'), ('an', 'DT'), ('indistinct', 'JJ'), ('remembrance', 'NN'), ('of', 'IN'), ('her', 'PRP$'), ('caresses', 'NNS'), (';', ':'), ('and', 'CC'), ('her', 'PRP$'), ('place', 'NN'), ('had', 'VBD'), ('been', 'VBN'), ('supplied', 'VBN'), ('by', 'IN'), ('an', 'DT'), ('excellent', 'JJ'), ('woman', 'NN'), ('as', 'IN'), ('governess', 'NN'), (',', ','), ('who', 'WP'), ('had', 'VBD'), ('fallen', 'VBN'), ('little', 'JJ'), ('short', 'JJ'), ('of', 'IN'), ('a', 'DT'), ('mother', 'NN'), ('in', 'IN'), ('affection', 'NN'), ('.', '.')]\n",
            "[('Sixteen', 'JJ'), ('years', 'NNS'), ('had', 'VBD'), ('Miss', 'NNP'), ('Taylor', 'NNP'), ('been', 'VBN'), ('in', 'IN'), ('Mr.', 'NNP'), ('Woodhouse', 'NNP'), (\"'s\", 'POS'), ('family', 'NN'), (',', ','), ('less', 'CC'), ('as', 'IN'), ('a', 'DT'), ('governess', 'NN'), ('than', 'IN'), ('a', 'DT'), ('friend', 'NN'), (',', ','), ('very', 'RB'), ('fond', 'NN'), ('of', 'IN'), ('both', 'DT'), ('daughters', 'NNS'), (',', ','), ('but', 'CC'), ('particularly', 'RB'), ('of', 'IN'), ('Emma', 'NNP'), ('.', '.')]\n",
            "[('Between', 'NNP'), ('_them_', 'VBD'), ('it', 'PRP'), ('was', 'VBD'), ('more', 'RBR'), ('the', 'DT'), ('intimacy', 'NN'), ('of', 'IN'), ('sisters', 'NNS'), ('.', '.')]\n",
            "[('Even', 'RB'), ('before', 'IN'), ('Miss', 'NNP'), ('Taylor', 'NNP'), ('had', 'VBD'), ('ceased', 'VBN'), ('to', 'TO'), ('hold', 'VB'), ('the', 'DT'), ('nominal', 'JJ'), ('office', 'NN'), ('of', 'IN'), ('governess', 'NN'), (',', ','), ('the', 'DT'), ('mildness', 'NN'), ('of', 'IN'), ('her', 'PRP$'), ('temper', 'NN'), ('had', 'VBD'), ('hardly', 'RB'), ('allowed', 'VBN'), ('her', 'PRP'), ('to', 'TO'), ('impose', 'VB'), ('any', 'DT'), ('restraint', 'NN'), (';', ':'), ('and', 'CC'), ('the', 'DT'), ('shadow', 'NN'), ('of', 'IN'), ('authority', 'NN'), ('being', 'VBG'), ('now', 'RB'), ('long', 'RB'), ('passed', 'VBN'), ('away', 'RB'), (',', ','), ('they', 'PRP'), ('had', 'VBD'), ('been', 'VBN'), ('living', 'VBG'), ('together', 'RB'), ('as', 'IN'), ('friend', 'NN'), ('and', 'CC'), ('friend', 'VB'), ('very', 'RB'), ('mutually', 'RB'), ('attached', 'VBN'), (',', ','), ('and', 'CC'), ('Emma', 'NNP'), ('doing', 'VBG'), ('just', 'RB'), ('what', 'WP'), ('she', 'PRP'), ('liked', 'VBD'), (';', ':'), ('highly', 'RB'), ('esteeming', 'VBG'), ('Miss', 'NNP'), ('Taylor', 'NNP'), (\"'s\", 'POS'), ('judgment', 'NN'), (',', ','), ('but', 'CC'), ('directed', 'VBD'), ('chiefly', 'NN'), ('by', 'IN'), ('her', 'PRP$'), ('own', 'JJ'), ('.', '.')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**08.Named Entity Recognition using chunking method**"
      ],
      "metadata": {
        "id": "1mzEpQtQ-rqi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_gd83lq7_24W",
        "outputId": "4264c07d-9fee-49b0-8538-d14988726ae9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize, PunktSentenceTokenizer\n",
        "train=\"Sundaram Pichai is the CEO of GOOGLE COMPANY\"\n",
        "text=\"Sundaram Pichai is the CEO of GOOGLE COMPANY\"\n",
        "custom_sent_tokenizer=PunktSentenceTokenizer(train)\n",
        "tokenized=custom_sent_tokenizer.tokenize(text)\n",
        "print(tokenized)\n",
        "\n",
        "\n",
        "def process_content():\n",
        "  try:\n",
        "    for i in tokenized:\n",
        "      words=word_tokenize(i)\n",
        "      tagged=nltk.pos_tag(words)\n",
        "      chunks=nltk.ne_chunk(tagged)\n",
        "      print(chunks)\n",
        "      chunks.pretty_print(unicodelines=True)\n",
        "  except Exception as e:\n",
        "    print(str(e))\n",
        "\n",
        "process_content()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46C6T_fl8Fbx",
        "outputId": "52af257f-a1ec-4bcf-bf95-d0b0527af758"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Sundaram Pichai is the CEO of GOOGLE COMPANY']\n",
            "(S\n",
            "  (PERSON Sundaram/NNP)\n",
            "  (PERSON Pichai/NNP)\n",
            "  is/VBZ\n",
            "  the/DT\n",
            "  (ORGANIZATION CEO/NN of/IN)\n",
            "  (ORGANIZATION GOOGLE/NNP)\n",
            "  COMPANY/NNP)\n",
            "                               S                                                        \n",
            "  ┌──────┬─────────┬───────────┼───────────┬──────────────────┬──────────────────┐       \n",
            "  │      │         │         PERSON      PERSON          ORGANIZATION       ORGANIZATION\n",
            "  │      │         │           │           │        ┌─────────┴─────────┐        │       \n",
            "is/VBZ the/DT COMPANY/NNP Sundaram/NNP Pichai/NNP CEO/NN              of/IN  GOOGLE/NNP \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**09.Lemmatization**"
      ],
      "metadata": {
        "id": "KJ2wR3EeAKai"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UD32S-F4Af1L",
        "outputId": "84174fea-ba6a-4284-83ce-d8996f388017"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "wnl=WordNetLemmatizer()\n",
        "print(wnl.lemmatize(\"better\", pos = \"a\"))\n",
        "print (wnl.lemmatize (\"better\", pos=\"n\"))\n",
        "print(wnl.lemmatize (\"is\", pos = \"v\"))\n",
        "print (wnl. lemmatize (\"is\", pos = \"r\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lavi5J_vAOSI",
        "outputId": "f98cd0f5-6a30-42c8-81f7-97d364468e20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "good\n",
            "better\n",
            "be\n",
            "is\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**10.Document Classification**"
      ],
      "metadata": {
        "id": "uuztt5QoAyCF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('movie_reviews')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WhpXA1cQIN1h",
        "outputId": "ea2c90df-87cc-435e-b391-40802ff35222"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from nltk.corpus import movie_reviews\n",
        "from nltk import FreqDist,NaiveBayesClassifier\n",
        "from nltk.classify import accuracy"
      ],
      "metadata": {
        "id": "zSNsuqFZAOdG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "documents=[(list(movie_reviews.words(fileid)),category) for category in movie_reviews.categories() for fileid in movie_reviews.fileids(category)]\n",
        "random.shuffle(documents)\n",
        "all_words=FreqDist(w.lower() for w in movie_reviews.words())\n",
        "word_features=list(all_words) [:1000]\n",
        "def document_features(document):\n",
        "  document_words = set(document)\n",
        "  features = {}\n",
        "  for word in word_features:\n",
        "    features[\"contains ({})\".format(word)] = (word in document_words)\n",
        "  return features\n",
        "featuresets = [(document_features(d),c) for (d,c) in documents]\n",
        "train_set, test_set = featuresets[:900], featuresets [900:]\n",
        "classifier = NaiveBayesClassifier.train(train_set)\n",
        "print((accuracy(classifier, test_set))*100)\n",
        "classifier.show_most_informative_features(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y40k04gNAOgQ",
        "outputId": "359c6795-c3ab-4961-d4b5-8d16578b5572"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "77.0909090909091\n",
            "Most Informative Features\n",
            "        contains (worst) = True              neg : pos    =      5.5 : 1.0\n",
            "       contains (stupid) = True              neg : pos    =      4.6 : 1.0\n",
            "    contains (excellent) = True              pos : neg    =      3.7 : 1.0\n",
            "         contains (mess) = True              neg : pos    =      3.5 : 1.0\n",
            "     contains (powerful) = True              pos : neg    =      3.4 : 1.0\n",
            "      contains (reality) = True              pos : neg    =      3.1 : 1.0\n",
            "    contains (perfectly) = True              pos : neg    =      3.1 : 1.0\n",
            "     contains (personal) = True              pos : neg    =      2.9 : 1.0\n",
            "        contains (bunch) = True              neg : pos    =      2.8 : 1.0\n",
            "       contains (boring) = True              neg : pos    =      2.8 : 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "12.chunking operation"
      ],
      "metadata": {
        "id": "cj6BVfRKIfwi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import tree\n",
        "from nltk import *\n",
        "text='A dog chased a cat'\n",
        "tokens=word_tokenize(text)\n",
        "print(tokens)\n",
        "tag=nltk.pos_tag(tokens)\n",
        "print(tag)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2q7uRvXoIeBU",
        "outputId": "8787c4d7-ed5b-4ebd-e0b0-6fed5baede81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['A', 'dog', 'chased', 'a', 'cat']\n",
            "[('A', 'DT'), ('dog', 'NN'), ('chased', 'VBD'), ('a', 'DT'), ('cat', 'NN')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "grammer=\"NP:{<DT>?<JJ>*<NN.*>}\"\n",
        "cp=nltk.RegexpParser(grammer)\n",
        "result=cp.parse(tag)\n",
        "print(result)\n",
        "print(result.pformat_latex_qtree())\n",
        "result.pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yf46T-UTJNpR",
        "outputId": "e11e0790-adb8-4e11-d65e-fb14cfb9b89a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(S (NP A/DT dog/NN) chased/VBD (NP a/DT cat/NN))\n",
            "\\Tree [.S [.NP A/DT dog/NN ] chased/VBD [.NP a/DT cat/NN ] ]\n",
            "                      S                   \n",
            "     _________________|__________          \n",
            "    |            NP              NP       \n",
            "    |        ____|____       ____|____     \n",
            "chased/VBD A/DT     dog/NN a/DT     cat/NN\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**13.FREQ DISTRIBUTION**"
      ],
      "metadata": {
        "id": "Kj5cM5h5KC4W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import gutenberg\n",
        "from nltk import FreqDist\n",
        "nltk.download('gutenberg')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ypyzhvLKOMI",
        "outputId": "cdbf206b-8a99-45cf-f2ca-853908658a11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/gutenberg.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list_of_words=gutenberg.words('austen-persuasion.txt')\n",
        "fd=FreqDist(list_of_words)\n",
        "print('Total number of tokens: '+str(fd.N()))\n",
        "print('number of unique tokens: '+str(fd.B()))\n",
        "print('Top 10 tokens:')\n",
        "for token, freq in fd.most_common(10):\n",
        "  print(token+'\\t'+str(freq))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09ZNkzVPKZzx",
        "outputId": "3e8e21ed-87b6-4ffe-8eb6-89912d745cd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of tokens: 98171\n",
            "number of unique tokens: 6132\n",
            "Top 10 tokens:\n",
            ",\t6750\n",
            "the\t3120\n",
            "to\t2775\n",
            ".\t2741\n",
            "and\t2739\n",
            "of\t2564\n",
            "a\t1529\n",
            "in\t1346\n",
            "was\t1330\n",
            ";\t1290\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Multi class classification**"
      ],
      "metadata": {
        "id": "l10SBJthLVT6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZmJ0VueqLUQ7",
        "outputId": "3e03fde0-af6f-4729-f16a-cb321c46f739"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n"
      ],
      "metadata": {
        "id": "QMzrxAYZKjP8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv('/content/sample_data/Twitter sentiment extraction - train.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "7Or8UHsONLkY",
        "outputId": "7ce19581-cf26-40f0-8ad5-1cbe5bf41e26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       textID                                               text  \\\n",
              "0  cb774db0d1                I`d have responded, if I were going   \n",
              "1  549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
              "2  088c60f138                          my boss is bullying me...   \n",
              "3  9642c003ef                     what interview! leave me alone   \n",
              "4  358bd9e861   Sons of ****, why couldn`t they put them on t...   \n",
              "\n",
              "                         selected_text sentiment  \n",
              "0  I`d have responded, if I were going   neutral  \n",
              "1                             Sooo SAD  negative  \n",
              "2                          bullying me  negative  \n",
              "3                       leave me alone  negative  \n",
              "4                        Sons of ****,  negative  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7a5f08a3-acea-4d0b-8de2-53a9d43783a2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>textID</th>\n",
              "      <th>text</th>\n",
              "      <th>selected_text</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>cb774db0d1</td>\n",
              "      <td>I`d have responded, if I were going</td>\n",
              "      <td>I`d have responded, if I were going</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>549e992a42</td>\n",
              "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
              "      <td>Sooo SAD</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>088c60f138</td>\n",
              "      <td>my boss is bullying me...</td>\n",
              "      <td>bullying me</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9642c003ef</td>\n",
              "      <td>what interview! leave me alone</td>\n",
              "      <td>leave me alone</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>358bd9e861</td>\n",
              "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
              "      <td>Sons of ****,</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7a5f08a3-acea-4d0b-8de2-53a9d43783a2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7a5f08a3-acea-4d0b-8de2-53a9d43783a2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7a5f08a3-acea-4d0b-8de2-53a9d43783a2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4051ac2e-a174-41ca-bf5f-eb376b79e1ba\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4051ac2e-a174-41ca-bf5f-eb376b79e1ba')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4051ac2e-a174-41ca-bf5f-eb376b79e1ba button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GzG3vpzFNYe6",
        "outputId": "2360353a-520c-4af2-af59-f790c7f46242"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 27481 entries, 0 to 27480\n",
            "Data columns (total 4 columns):\n",
            " #   Column         Non-Null Count  Dtype \n",
            "---  ------         --------------  ----- \n",
            " 0   textID         27481 non-null  object\n",
            " 1   text           27480 non-null  object\n",
            " 2   selected_text  27480 non-null  object\n",
            " 3   sentiment      27481 non-null  object\n",
            "dtypes: object(4)\n",
            "memory usage: 858.9+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['text']=df['text'].str.strip('\"')\n",
        "df.dropna(inplace=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "vi3tG2xKNYnQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment_mapping={'negative':0,'neutral':1,'positive':2}\n",
        "df['sentiment']=df['sentiment'].map(sentiment_mapping)\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "eVW9N_71NYpy",
        "outputId": "27d604a3-a1a0-4418-f824-487d7447c711"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           textID                                               text  \\\n",
              "0      cb774db0d1                I`d have responded, if I were going   \n",
              "1      549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
              "2      088c60f138                          my boss is bullying me...   \n",
              "3      9642c003ef                     what interview! leave me alone   \n",
              "4      358bd9e861   Sons of ****, why couldn`t they put them on t...   \n",
              "...           ...                                                ...   \n",
              "27476  4eac33d1c0   wish we could come see u on Denver  husband l...   \n",
              "27477  4f4c4fc327   I`ve wondered about rake to.  The client has ...   \n",
              "27478  f67aae2310   Yay good for both of you. Enjoy the break - y...   \n",
              "27479  ed167662a5                         But it was worth it  ****.   \n",
              "27480  6f7127d9d7     All this flirting going on - The ATG smiles...   \n",
              "\n",
              "                                           selected_text  sentiment  \n",
              "0                    I`d have responded, if I were going          1  \n",
              "1                                               Sooo SAD          0  \n",
              "2                                            bullying me          0  \n",
              "3                                         leave me alone          0  \n",
              "4                                          Sons of ****,          0  \n",
              "...                                                  ...        ...  \n",
              "27476                                             d lost          0  \n",
              "27477                                      , don`t force          0  \n",
              "27478                          Yay good for both of you.          2  \n",
              "27479                         But it was worth it  ****.          2  \n",
              "27480  All this flirting going on - The ATG smiles. Y...          1  \n",
              "\n",
              "[27480 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-13757d69-ff30-43d7-be83-2e5bad45aff0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>textID</th>\n",
              "      <th>text</th>\n",
              "      <th>selected_text</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>cb774db0d1</td>\n",
              "      <td>I`d have responded, if I were going</td>\n",
              "      <td>I`d have responded, if I were going</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>549e992a42</td>\n",
              "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
              "      <td>Sooo SAD</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>088c60f138</td>\n",
              "      <td>my boss is bullying me...</td>\n",
              "      <td>bullying me</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9642c003ef</td>\n",
              "      <td>what interview! leave me alone</td>\n",
              "      <td>leave me alone</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>358bd9e861</td>\n",
              "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
              "      <td>Sons of ****,</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27476</th>\n",
              "      <td>4eac33d1c0</td>\n",
              "      <td>wish we could come see u on Denver  husband l...</td>\n",
              "      <td>d lost</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27477</th>\n",
              "      <td>4f4c4fc327</td>\n",
              "      <td>I`ve wondered about rake to.  The client has ...</td>\n",
              "      <td>, don`t force</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27478</th>\n",
              "      <td>f67aae2310</td>\n",
              "      <td>Yay good for both of you. Enjoy the break - y...</td>\n",
              "      <td>Yay good for both of you.</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27479</th>\n",
              "      <td>ed167662a5</td>\n",
              "      <td>But it was worth it  ****.</td>\n",
              "      <td>But it was worth it  ****.</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27480</th>\n",
              "      <td>6f7127d9d7</td>\n",
              "      <td>All this flirting going on - The ATG smiles...</td>\n",
              "      <td>All this flirting going on - The ATG smiles. Y...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>27480 rows × 4 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-13757d69-ff30-43d7-be83-2e5bad45aff0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-13757d69-ff30-43d7-be83-2e5bad45aff0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-13757d69-ff30-43d7-be83-2e5bad45aff0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a4adb835-164b-4da5-84c8-56de5740275c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a4adb835-164b-4da5-84c8-56de5740275c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a4adb835-164b-4da5-84c8-56de5740275c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X=df['selected_text'].values\n",
        "y=df['sentiment'].values\n",
        "X_train, X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)"
      ],
      "metadata": {
        "id": "5RJJktLLOFsb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(num_words=5000)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "X_train_seq=tokenizer.texts_to_sequences(X_train)\n",
        "\n",
        "X_test_seq=tokenizer.texts_to_sequences(X_test)\n",
        "X_train_padded = pad_sequences(X_train_seq, maxlen=100)\n",
        "X_test_padded = pad_sequences(X_test_seq, maxlen=100)"
      ],
      "metadata": {
        "id": "HtLrAPDROgtV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 3\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=5000, output_dim=50, input_length=100))\n",
        "model.add(LSTM(units=128,return_sequences=True))\n",
        "model.add(LSTM(units=64))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(units=num_classes, activation='softmax'))\n",
        "\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "y_train_one_hot = to_categorical(y_train, num_classes=num_classes)\n",
        "y_test_one_hot = to_categorical(y_test, num_classes=num_classes)\n",
        "\n",
        "\n",
        "model.fit(X_train_padded, y_train_one_hot, epochs=10, batch_size=64, validation_split=0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aVAWZRqEPAJN",
        "outputId": "5d4739c9-4827-4376-ae2e-64fe10413fd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "310/310 [==============================] - 125s 389ms/step - loss: 0.7722 - accuracy: 0.6465 - val_loss: 0.5646 - val_accuracy: 0.7799\n",
            "Epoch 2/10\n",
            "310/310 [==============================] - 119s 386ms/step - loss: 0.4471 - accuracy: 0.8307 - val_loss: 0.4670 - val_accuracy: 0.8217\n",
            "Epoch 3/10\n",
            "310/310 [==============================] - 122s 394ms/step - loss: 0.3472 - accuracy: 0.8727 - val_loss: 0.4507 - val_accuracy: 0.8395\n",
            "Epoch 4/10\n",
            "310/310 [==============================] - 122s 392ms/step - loss: 0.2992 - accuracy: 0.8929 - val_loss: 0.4633 - val_accuracy: 0.8377\n",
            "Epoch 5/10\n",
            "310/310 [==============================] - 126s 405ms/step - loss: 0.2780 - accuracy: 0.9004 - val_loss: 0.4791 - val_accuracy: 0.8349\n",
            "Epoch 6/10\n",
            "310/310 [==============================] - 122s 395ms/step - loss: 0.2514 - accuracy: 0.9103 - val_loss: 0.5114 - val_accuracy: 0.8226\n",
            "Epoch 7/10\n",
            "310/310 [==============================] - 134s 432ms/step - loss: 0.2312 - accuracy: 0.9162 - val_loss: 0.5477 - val_accuracy: 0.8154\n",
            "Epoch 8/10\n",
            "310/310 [==============================] - 122s 394ms/step - loss: 0.2091 - accuracy: 0.9269 - val_loss: 0.5744 - val_accuracy: 0.8240\n",
            "Epoch 9/10\n",
            "310/310 [==============================] - 122s 395ms/step - loss: 0.1898 - accuracy: 0.9309 - val_loss: 0.6317 - val_accuracy: 0.8163\n",
            "Epoch 10/10\n",
            "310/310 [==============================] - 120s 386ms/step - loss: 0.1773 - accuracy: 0.9360 - val_loss: 0.6789 - val_accuracy: 0.8249\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7fdd851bfa90>"
            ]
          },
          "metadata": {},
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss,accuracy=model.evaluate(X_test_padded,y_test_one_hot)\n",
        "print(f\"Test Loss: {loss*100:.4f}, Test Accuracy: {accuracy*100:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A3quH1vnRQnV",
        "outputId": "cfd8fd99-cbc8-4c40-c216-f5aa3b4afede"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "172/172 [==============================] - 14s 81ms/step - loss: 0.6980 - accuracy: 0.8126\n",
            "Test Loss: 69.8025, Test Accuracy: 81.2591\n"
          ]
        }
      ]
    }
  ]
}